import org.apache.spark.sql.DataFrame
import org.apache.spark.sql.functions._

def splitArray(df: DataFrame, n: Int): Array[Array[Int]] = {
  val arr = df.select(col("value").cast("Int")).as[Int].collect()
  val sortedArr = arr.sorted.reverse
  val subarrays = Array.fill(n)(Array.empty[Int])
  for (x <- sortedArr) {
    val idx = subarrays.zipWithIndex.minBy { case (subarray, _) => subarray.sum }._2
    subarrays(idx) :+= x
  }
  subarrays
}

val input = Seq(("a", "5"), ("b", "3"), ("c", "8"), ("d", "1"), ("e", "2"), ("f", "6"), ("g", "7"), ("h", "4")).toDF("id", "value")
val subarrays = splitArray(input, 3)
println(subarrays.map(_.mkString(", ")).mkString("\n"))
