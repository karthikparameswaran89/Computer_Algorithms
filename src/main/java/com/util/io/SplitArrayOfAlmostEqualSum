import org.apache.spark.sql.DataFrame
import org.apache.spark.sql.functions._

def splitArray(df: DataFrame, n: Int): Array[Array[Int]] = {
  val arr = df.select("value").as[Int].collect()
  val sortedArr = arr.sorted.reverse
  val subarrays = Array.fill(n)(Array.empty[Int])
  for (x <- sortedArr) {
    val idx = subarrays.zipWithIndex.minBy { case (subarray, _) => subarray.sum }._2
    subarrays(idx) :+= x
  }
  subarrays
}

val arr = Array.range(1, 100)
val n = 4
val df = arr.toSeq.toDF("value")
val subarrays = splitArray(df, n)
println(subarrays.map(_.mkString(", ")).mkString("\n"))
