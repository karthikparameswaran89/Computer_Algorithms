# Create a temporary Delta table
from pyspark.sql import SparkSession
import uuid

spark = SparkSession.builder.getOrCreate()

temp_table_name = f"temp_test_table_{uuid.uuid4().hex[:8]}"
temp_table_path = f"/tmp/{temp_table_name}"

# Write a dummy table
df = spark.range(1).toDF("id")
df.write.format("delta").save(f"dbfs:{temp_table_path}")

# Get actual file path
actual_path = spark.read.format("delta").load(f"dbfs:{temp_table_path}").inputFiles()[0]
print("Actual backing path:", actual_path)

# Cleanup
dbutils.fs.rm(f"dbfs:{temp_table_path}", True)
