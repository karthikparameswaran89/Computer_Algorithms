import org.apache.spark.sql.functions._
import org.apache.spark.sql.expressions.UserDefinedFunction

// Step 1: Target columns only â€” from level1_code to level20_code
val levelCols = (1 to 20).map(i => s"level${i}_code")

// Step 2: UDF to find second-last different value
val findSecondLastDifferent: UserDefinedFunction = udf((codes: Seq[String]) => {
  if (codes == null || codes.size < 2) return null
  for (i <- (codes.size - 1) to 1 by -1) {
    if (codes(i) != codes(i - 1)) {
      return codes(i - 1)
    }
  }
  null
})

// Step 3: Apply to your DataFrame
val dfWithDiff = df.withColumn(
  "second_last_diff_value",
  findSecondLastDifferent(array(levelCols.map(col): _*))
)
